# Research Summaries

Summarised external research articles and benchmark reports referenced by
the model-family dossiers and team model guides in this section.
Summaries are written from publicly available content; original sources
are linked in each file.

## Articles

| File | Source | Topic |
| --- | --- | --- |
| [swe-bench-leaderboard-feb-2026.md](./swe-bench-leaderboard-feb-2026.md) | swebench.com, marc0.dev, simonwillison.net | SWE-bench Verified rankings for Feb 2026 |
| [aider-polyglot-leaderboard-2025.md](./aider-polyglot-leaderboard-2025.md) | aider.chat, epoch.ai, simonwillison.net | Aider polyglot coding benchmark methodology and results |
| [best-llm-for-coding-teams-2026.md](./best-llm-for-coding-teams-2026.md) | morphllm.com, kanaries.net, builder.io, noviai.ai | Practical coding model selection across team roles |

## How to Use

1. Treat these summaries as secondary evidence to cross-check
   claims in the model-family dossiers.
2. When a dossier cites a source, look it up here for the full
   context and caveats.
3. Summaries note where the original page was accessible vs
   where content comes from search snippets only.
4. Refresh these summaries whenever a new benchmark cycle is
   published (typically every 2â€“3 months for SWE-bench).
